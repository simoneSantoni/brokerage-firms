{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Topic-modelling\" data-toc-modified-id=\"Topic-modelling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Topic modelling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Set-working-directory\" data-toc-modified-id=\"Set-working-directory-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Set working directory</a></span></li><li><span><a href=\"#Alert-Function\" data-toc-modified-id=\"Alert-Function-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Alert Function</a></span></li><li><span><a href=\"#Import-Data\" data-toc-modified-id=\"Import-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Import Data</a></span></li><li><span><a href=\"#Stop-Words\" data-toc-modified-id=\"Stop-Words-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Stop Words</a></span></li><li><span><a href=\"#Model-Preprocessing-Functions\" data-toc-modified-id=\"Model-Preprocessing-Functions-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Model Preprocessing Functions</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling\n",
    "\n",
    "**Frequency of dominant topics in documents**\n",
    "\n",
    "\n",
    "    Date: 03/12/19\n",
    "    Author: Avery\n",
    "    Source Code: Simone and Toni\n",
    "    Last Updated: 06/12/19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:12:46.361570Z",
     "start_time": "2019-12-14T21:12:42.954849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting tools\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#NLTK\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "if 'nlp' not in locals():\n",
    "    # nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from glob import glob\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Text Analysis (uncomment if running for first time)\n",
    "# ! wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "# ! unzip mallet-2.0.8.zip\n",
    "MALLET_PATH = 'mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:12:46.372511Z",
     "start_time": "2019-12-14T21:12:46.363034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/averysoh/Google Drive (racass1234@gmail.com)')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import *\n",
    "#current working directory\n",
    "current_dir = Path.cwd()\n",
    "#go up 1 level to the 1st parent directory\n",
    "Par1_dir = current_dir.parents[0]\n",
    "\n",
    "Par1_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alert Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:12:46.377509Z",
     "start_time": "2019-12-14T21:12:46.374413Z"
    }
   },
   "outputs": [],
   "source": [
    "def allDone():\n",
    "    '''this function outputs a short audio when called. \n",
    "    Typically this is used to signal a task completion'''\n",
    "    \n",
    "    display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:12:46.389866Z",
     "start_time": "2019-12-14T21:12:46.379443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "Whats happening here:\n",
    "- Importing a test file to process the data and see the visualisation \n",
    "- slice the dataframe into yearly slices, then take a random sample of size=100k for each year and save the DF samples in a list.\n",
    "- delete the DF imported and call for garbage collection to clear the memory\n",
    "\n",
    "Reason for sampling will be mentioned below in another step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:13:27.553571Z",
     "start_time": "2019-12-14T21:13:09.441621Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ai_project/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the file and data directories\n",
    "df_filename = 'globe_Machine Learning_all_.csv'\n",
    "df_data_dir = Par1_dir /'AI Project'/'Python Env' / 'DataFrames'/ 'AI_datasets' / 'globe_ai_13_18'/ df_filename\n",
    "\n",
    "#import only the required columns from the DF\n",
    "df = pd.read_csv(df_data_dir, usecols=['tweet', 'date/time', 'search'])\n",
    "\n",
    "#find dataframe's search word, and remove quotations f present\n",
    "search_word = df.head(1).search.item().replace('\"', '').replace(\"'\",\"\")\n",
    "#drop unused columns\n",
    "df = df.loc[:, ['tweet', 'date/time']]\n",
    "\n",
    "df_list = []\n",
    "# #create a random Sample of 100k for each year & drop NAs\n",
    "for x in range(2013,2019):\n",
    "    globals()['df_%s' % x] = df.loc[(df['date/time']>=str(x)+'-01-01 00:00:00+00:00') & (df['date/time']<str(x+1)+'-01-01 00:00:00+00:00'),: ].copy()\n",
    "    n = min(100000, len(globals()['df_%s' % x]))\n",
    "    globals()['df_%s' % x] = globals()['df_%s' % x].sample(n=n, random_state=11).dropna(subset=['tweet'])\n",
    "    df_list.append(globals()['df_%s' % x])\n",
    "    del globals()['df_%s' % x]\n",
    "\n",
    "#delete the big DF\n",
    "del df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T17:42:22.663771Z",
     "start_time": "2019-12-06T17:42:07.591969Z"
    }
   },
   "source": [
    "## Stop Words\n",
    "\n",
    "Process developed by Toni, refer to file \"Yearly Topic Models.ipynb\" in \"Pcode\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:13:48.387032Z",
     "start_time": "2019-12-14T21:13:48.379338Z"
    }
   },
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#NLTK english stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "#extend the list with a peronal list of stopwords\n",
    "stop_words.extend(['from', 'need','thank','thing','something', 'see', 'say', 'well','people', 'change', 'com',\\\n",
    "                   'go', 'put', 'give','twitter','pic', \\\n",
    "                   'subject', 're', 'edu', 'could', 'be', 'make', 'not', 'make','find','let','may','see', 'would',\\\n",
    "                   'come', 'sure', 'ever', 'tell', 'use', 'not', 'doing', 'be', 'get','want'])\n",
    "#extend the search word\n",
    "stop_words.extend(['artificial intelligence', '#ai', '#ml', '#nlp', 'analytics', 'data mining',\n",
    "                  'deep mining', 'machine learning', 'natural language processing', 'neural network'\n",
    "                  'pattern recognition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preprocessing Functions\n",
    "\n",
    "Process developed by Toni, refer to file \"Yearly Topic Models.ipynb\" in \"Pcode\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:13:50.038302Z",
     "start_time": "2019-12-14T21:13:50.024340Z"
    }
   },
   "outputs": [],
   "source": [
    "### Tokenize words and Clean-up text\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "###Remove Stopwords, Make Bigrams and Lemmatize\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(bigram_mod, texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "def lda_preprocessing(df):\n",
    "    ### Remove emails, newline characters, and links\n",
    "    # Convert to list\n",
    "    data = df.tweet.values.tolist()\n",
    "\n",
    "    # Remove Emails\n",
    "    data = [re.sub('\\S*@\\S*\\s?', '', str(tweet)) for tweet in data]\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = [re.sub('\\s+', ' ', tweet) for tweet in data]\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = [re.sub(\"\\'\", \"\", tweet) for tweet in data]\n",
    "\n",
    "    #Remove links\n",
    "    data = [re.sub(r\"http\\S+\", \"\", tweet) for tweet in data]\n",
    "\n",
    "    #make lower case\n",
    "    data = [tweet.lower() for tweet in data]\n",
    "    \n",
    "    # Tokenize words and Clean-up text\n",
    "    data_words = list(sent_to_words(data))\n",
    "\n",
    "    ###Creating Bigram and Trigram Models\n",
    "    # Build the bigram and trigram models\n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "    trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "    # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "    \n",
    "    # Remove Stop Words\n",
    "    data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "    # Form Bigrams\n",
    "    data_words_bigrams = make_bigrams(bigram_mod, data_words_nostops)\n",
    "\n",
    "    # Do lemmatization keeping only noun, adj, vb, adv\n",
    "    data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN','ADJ','ADV', 'VERB'])\n",
    "    data_lemmatized = remove_stopwords(data_lemmatized)\n",
    "\n",
    "    ###Create the Dictionary and Corpus needed for Topic Modeling¶\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "    # Create Corpus\n",
    "    texts = data_lemmatized\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "        \n",
    "    return data_lemmatized, corpus, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T22:29:17.353597Z",
     "start_time": "2019-12-06T22:29:17.351097Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "# Testing with sample DF\n",
    "# 2013 df testing\n",
    "\n",
    "#df = df_list[0]\n",
    "#data_lemmatized, CORPUS, id2word = lda_preprocessing(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:14:17.172652Z",
     "start_time": "2019-12-14T21:13:56.323408Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-33cd7cafe823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     df = df_list[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdata_lemmatized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCORPUS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#get current working directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c4e7f0f45efa>\u001b[0m in \u001b[0;36mlda_preprocessing\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Do lemmatization keeping only noun, adj, vb, adv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mdata_lemmatized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_words_bigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_postags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NOUN'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ADJ'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ADV'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VERB'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mdata_lemmatized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c4e7f0f45efa>\u001b[0m in \u001b[0;36mlemmatization\u001b[0;34m(texts, allowed_postags)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtexts_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtexts_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_postags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtexts_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/api.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(seqs_in)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/api.py\u001b[0m in \u001b[0;36muniqued_fwd\u001b[0;34m(X, drop)\u001b[0m\n\u001b[1;32m    377\u001b[0m         )\n\u001b[1;32m    378\u001b[0m         \u001b[0mX_uniq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mY_uniq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_Y_uniq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_uniq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_uniq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mY_uniq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/thinc/neural/_classes/maxout.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X__bi, drop)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdrop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mdrop\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX__bi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.models.wrappers.ldamallet import malletmodel2ldamodel\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "#     df = df_list[1]\n",
    "for df in df_list:\n",
    "    data_lemmatized, CORPUS, id2word = lda_preprocessing(df)\n",
    "\n",
    "    #get current working directory\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    #set the number of workers to the number of cores available\n",
    "    workers = cpu_count() \n",
    "\n",
    "    # Set number of topics\n",
    "    NUM_TOPICS = 20\n",
    "\n",
    "    ldamallet = LdaMallet(MALLET_PATH, corpus=CORPUS, num_topics=NUM_TOPICS, id2word=id2word,\n",
    "                                      random_seed =11,workers=workers)\n",
    "\n",
    "    # Transform model weights from MALLET to GENSIM\n",
    "    lda_model = malletmodel2ldamodel(ldamallet)\n",
    "\n",
    "    ############################\n",
    "    # Get doc-topic probability#\n",
    "    ############################\n",
    "\n",
    "    # get transformed corpus as per the LDA model\n",
    "    TRANSF_CORPUS = lda_model.get_document_topics(CORPUS)\n",
    "\n",
    "    # rearrange data on document-topic pairs probabilities\n",
    "    DOC_TOPIC_M = []\n",
    "\n",
    "    for id, doc in enumerate(TRANSF_CORPUS):\n",
    "        for topic in np.arange(0, 20, 1):\n",
    "            topic_n = doc[topic][0]\n",
    "            topic_prob = doc[topic][1] \n",
    "            DOC_TOPIC_M.append([id, topic, topic_prob])\n",
    "\n",
    "    DF = pd.DataFrame(DOC_TOPIC_M)\n",
    "\n",
    "    # rename columns\n",
    "    OLD_NAMES = [0, 1, 2]\n",
    "    NEW_NAMES = ['doc_id', 'topic_n', 'prob']\n",
    "    COLS = dict(zip(OLD_NAMES, NEW_NAMES))\n",
    "    DF.rename(columns=COLS, inplace=True)\n",
    "\n",
    "    # Keep only dominant topic for vis\n",
    "    GR = DF.groupby('doc_id')\n",
    "    DF.loc[:, 'max'] = GR['prob'].transform(np.max)\n",
    "    DF.loc[:, 'first_topic'] = 0\n",
    "    DF.loc[DF['prob'] == DF['max'], 'first_topic'] = 1\n",
    "    FIRST_TOPIC = DF.loc[DF['first_topic'] == 1]\n",
    "\n",
    "    # write data to file\n",
    "    filename = search_word + 'dom_topic'+ min(df.loc[:,'date/time'])[:10]+\"_\" + max(df.loc[:,'date/time'])[:10] + '.csv'\n",
    "    save_dir = Par1_dir /'AI Project'/'Avery_output' / filename\n",
    "    FIRST_TOPIC.to_csv(save_dir, index=True)\n",
    "\n",
    "\n",
    "    # Store a dataset for visualistion later\n",
    "    year_name = min(df.loc[:,'date/time'])[:4]\n",
    "    VIS_DF = pd.DataFrame(FIRST_TOPIC.topic_n.value_counts()).reset_index()\n",
    "    # Add a rank level\n",
    "    VIS_DF.index += 1 \n",
    "    VIS_DF.reset_index(inplace=True)\n",
    "\n",
    "    # rename columns\n",
    "    OLD_NAMES = ['level_0', 'index', 'topic_n']\n",
    "    NEW_NAMES = ['rank', 'topic_n', 'freq']\n",
    "    COLS = dict(zip(OLD_NAMES, NEW_NAMES))\n",
    "    VIS_DF.rename(columns=COLS, inplace=True)\n",
    "\n",
    "    # Add the current year\n",
    "    VIS_DF['year'] = int(year_name)\n",
    "\n",
    "    vis_filename = year_name + '.csv'\n",
    "    foldername = search_word + '_vis_df'\n",
    "    save_dir2 = Par1_dir /'AI Project'/'Avery_output' / foldername / vis_filename\n",
    "    VIS_DF.to_csv(save_dir2, index=True)\n",
    "\n",
    "    del DF\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:14:36.177309Z",
     "start_time": "2019-12-14T21:14:36.171654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/averysoh/Google Drive (racass1234@gmail.com)/AI Project/Avery_output/Machine Learning_vis_df/2013.csv',\n",
       " '/Users/averysoh/Google Drive (racass1234@gmail.com)/AI Project/Avery_output/Machine Learning_vis_df/2014.csv',\n",
       " '/Users/averysoh/Google Drive (racass1234@gmail.com)/AI Project/Avery_output/Machine Learning_vis_df/2015.csv',\n",
       " '/Users/averysoh/Google Drive (racass1234@gmail.com)/AI Project/Avery_output/Machine Learning_vis_df/2016.csv',\n",
       " '/Users/averysoh/Google Drive (racass1234@gmail.com)/AI Project/Avery_output/Machine Learning_vis_df/2017.csv',\n",
       " '/Users/averysoh/Google Drive (racass1234@gmail.com)/AI Project/Avery_output/Machine Learning_vis_df/2018.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all the file names in the folder for the visualisation\n",
    "df_files = sorted(glob(str(Par1_dir /'AI Project'/'Avery_output'/ 'Machine Learning_vis_df'/'*')))\n",
    "df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-14T21:14:37.589176Z",
     "start_time": "2019-12-14T21:14:36.974675Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>topic_n</th>\n",
       "      <th>freq</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5451</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5068</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4785</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4766</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4719</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>5452</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5203</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>5167</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>5097</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>4822</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank  topic_n  freq  year\n",
       "0      1       13  5451  2013\n",
       "1      2       18  5068  2013\n",
       "2      3        8  4785  2013\n",
       "3      4       10  4766  2013\n",
       "4      5        4  4719  2013\n",
       "..   ...      ...   ...   ...\n",
       "15    16       19  5452  2018\n",
       "16    17       15  5203  2018\n",
       "17    18       10  5167  2018\n",
       "18    19        7  5097  2018\n",
       "19    20       13  4822  2018\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read All the files from df_files\n",
    "vis_list=[]\n",
    "\n",
    "for x in range(len(df_files)):\n",
    "    globals()['df_%s' % df_files[x][-8:-4]] = pd.read_csv(df_files[x])\n",
    "    vis_list.append(globals()['df_%s' % df_files[x][-8:-4]])\n",
    "    del globals()['df_%s' % df_files[x][-8:-4]]\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "# Store as a single df\n",
    "vis_df = pd.concat(vis_list)\n",
    "vis_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "vis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T10:03:43.809221Z",
     "start_time": "2019-12-12T10:03:43.450422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"6585\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"6585\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"6585\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '6585' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"6585\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"6585\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"6585\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '6585' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"6585\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"43e2a0d7-8fba-4d0e-b9ef-ebcf169b7d1f\" data-root-id=\"6591\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"c5ca3b50-d612-487e-b629-1384f820b8ea\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"6602\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"6606\",\"type\":\"Grid\"},{\"id\":\"6611\",\"type\":\"Grid\"}],\"left\":[{\"id\":\"6607\",\"type\":\"LinearAxis\"}],\"plot_height\":1000,\"plot_width\":800,\"renderers\":[{\"id\":\"6616\",\"type\":\"GlyphRenderer\"},{\"id\":\"6621\",\"type\":\"GlyphRenderer\"},{\"id\":\"6626\",\"type\":\"GlyphRenderer\"},{\"id\":\"6631\",\"type\":\"GlyphRenderer\"}],\"right\":[{\"id\":\"6635\",\"type\":\"ColorBar\"}],\"title\":{\"id\":\"6592\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"6612\",\"type\":\"Toolbar\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"6594\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"6598\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"6596\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"6600\",\"type\":\"LinearScale\"}},\"id\":\"6591\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"Topic Number\",\"@topic_n\"],[\"Frequency as Dominant Topic\",\"@freq\"],[\"Rank\",\"@rank\"]]},\"id\":\"6633\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"6835\",\"type\":\"Selection\"},{\"attributes\":{\"formatter\":{\"id\":\"6826\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"6608\",\"type\":\"BasicTicker\"}},\"id\":\"6607\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"6586\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"6629\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"6630\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"6632\",\"type\":\"CDSView\"}},\"id\":\"6631\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"6836\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"callback\":null,\"data\":{\"freq\":[5451,5068,4785,4766,4719,4711,4708,4609,4597,4549,4524,4462,4462,4436,4422,4306,4213,4193,4165,4146,6841,6841,6764,6707,6694,6344,6248,6142,6126,5916,5907,5890,5816,5701,5654,5610,5558,5543,4908,4423,7755,7304,7059,6875,6868,6858,6679,6665,6570,6498,6482,6319,6249,6203,6195,6164,5936,5925,5722,5620,6956,6503,6492,6371,6308,6280,6197,6177,6069,5996,5935,5924,5815,5744,5710,5696,5617,5579,5497,5449,6815,6753,6745,6107,6035,5999,5998,5808,5767,5749,5748,5689,5665,5643,5607,5551,5446,5424,5311,5302,7660,6975,6852,6650,6106,6059,5954,5928,5839,5834,5665,5636,5478,5478,5474,5452,5203,5167,5097,4822],\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"rank\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"topic_n\":[13,18,8,10,4,9,7,17,19,15,16,11,3,2,12,0,1,14,5,6,10,8,12,3,5,17,1,2,13,11,0,18,19,4,7,15,16,14,6,9,1,7,14,17,0,6,2,3,15,16,10,19,4,18,12,8,11,13,5,9,2,15,19,13,4,7,9,5,16,10,14,17,0,8,11,12,6,3,1,18,13,14,10,4,1,17,11,16,6,8,18,7,2,0,12,5,3,15,19,9,16,18,5,4,0,14,11,12,2,8,1,6,17,3,9,19,15,10,7,13],\"year\":[2013,2013,2013,2013,2013,2013,2013,2013,2013,2013,2013,2013,2013,2013,2013,2013,2013,2013,2013,2013,2014,2014,2014,2014,2014,2014,2014,2014,2014,2014,2014,2014,2014,2014,2014,2014,2014,2014,2014,2014,2015,2015,2015,2015,2015,2015,2015,2015,2015,2015,2015,2015,2015,2015,2015,2015,2015,2015,2015,2015,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2016,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018]},\"selected\":{\"id\":\"6837\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"6836\",\"type\":\"UnionRenderers\"}},\"id\":\"6586\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":30},\"x\":{\"field\":\"year\"},\"y\":{\"field\":\"rank\"}},\"id\":\"6630\",\"type\":\"Circle\"},{\"attributes\":{\"callback\":null,\"data\":{\"freq\":[4213,6248,7755,5497,6035,5665],\"index\":[16,6,0,18,4,10],\"rank\":[17,7,1,19,5,11],\"topic_n\":[1,1,1,1,1,1],\"year\":[2013,2014,2015,2016,2017,2018]},\"selected\":{\"id\":\"6831\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"6830\",\"type\":\"UnionRenderers\"}},\"id\":\"6587\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"line_alpha\":0.5,\"line_color\":\"grey\",\"line_width\":4,\"x\":{\"field\":\"year\"},\"y\":{\"field\":\"rank\"}},\"id\":\"6619\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"6587\",\"type\":\"ColumnDataSource\"}},\"id\":\"6617\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null,\"data\":{\"freq\":[4436,6142,6679,6956,5665,5839],\"index\":[13,7,6,0,12,8],\"rank\":[14,8,7,1,13,9],\"topic_n\":[2,2,2,2,2,2],\"year\":[2013,2014,2015,2016,2017,2018]},\"selected\":{\"id\":\"6833\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"6832\",\"type\":\"UnionRenderers\"}},\"id\":\"6588\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"6832\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"6829\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_color\":{\"field\":\"rank\",\"transform\":{\"id\":\"6590\",\"type\":\"LinearColorMapper\"}},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":30},\"x\":{\"field\":\"year\"},\"y\":{\"field\":\"rank\"}},\"id\":\"6629\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"6837\",\"type\":\"Selection\"},{\"attributes\":{\"callback\":null},\"id\":\"6596\",\"type\":\"DataRange1d\"},{\"attributes\":{\"source\":{\"id\":\"6586\",\"type\":\"ColumnDataSource\"}},\"id\":\"6632\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null},\"id\":\"6594\",\"type\":\"DataRange1d\"},{\"attributes\":{\"line_alpha\":0.5,\"line_color\":\"grey\",\"line_width\":4,\"x\":{\"field\":\"year\"},\"y\":{\"field\":\"rank\"}},\"id\":\"6624\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"6830\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"6833\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"6600\",\"type\":\"LinearScale\"},{\"attributes\":{\"formatter\":{\"id\":\"6824\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"6603\",\"type\":\"BasicTicker\"}},\"id\":\"6602\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"6831\",\"type\":\"Selection\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"6608\",\"type\":\"BasicTicker\"}},\"id\":\"6611\",\"type\":\"Grid\"},{\"attributes\":{\"text\":\"Dominant Topic Frequency\"},\"id\":\"6592\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"6603\",\"type\":\"BasicTicker\"},{\"attributes\":{\"source\":{\"id\":\"6588\",\"type\":\"ColumnDataSource\"}},\"id\":\"6622\",\"type\":\"CDSView\"},{\"attributes\":{\"ticker\":{\"id\":\"6603\",\"type\":\"BasicTicker\"}},\"id\":\"6606\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"6828\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"6826\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":4,\"x\":{\"field\":\"year\"},\"y\":{\"field\":\"rank\"}},\"id\":\"6625\",\"type\":\"Line\"},{\"attributes\":{\"color_mapper\":{\"id\":\"6590\",\"type\":\"LinearColorMapper\"},\"formatter\":{\"id\":\"6828\",\"type\":\"BasicTickFormatter\"},\"location\":[0,0],\"ticker\":{\"id\":\"6829\",\"type\":\"BasicTicker\"}},\"id\":\"6635\",\"type\":\"ColorBar\"},{\"attributes\":{\"data_source\":{\"id\":\"6587\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"6614\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"6615\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"6617\",\"type\":\"CDSView\"}},\"id\":\"6616\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"6608\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"6824\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"line_alpha\":0.5,\"line_color\":\"grey\",\"line_width\":4,\"x\":{\"field\":\"year\"},\"y\":{\"field\":\"rank\"}},\"id\":\"6614\",\"type\":\"Line\"},{\"attributes\":{\"callback\":null,\"data\":{\"freq\":[4462,6707,6665,5579,5446,5478],\"index\":[12,3,7,17,16,13],\"rank\":[13,4,8,18,17,14],\"topic_n\":[3,3,3,3,3,3],\"year\":[2013,2014,2015,2016,2017,2018]},\"selected\":{\"id\":\"6835\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"6834\",\"type\":\"UnionRenderers\"}},\"id\":\"6589\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"6633\",\"type\":\"HoverTool\"}]},\"id\":\"6612\",\"type\":\"Toolbar\"},{\"attributes\":{\"data_source\":{\"id\":\"6589\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"6624\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"6625\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"6627\",\"type\":\"CDSView\"}},\"id\":\"6626\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"6598\",\"type\":\"LinearScale\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":4,\"x\":{\"field\":\"year\"},\"y\":{\"field\":\"rank\"}},\"id\":\"6620\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"6834\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data_source\":{\"id\":\"6588\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"6619\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"6620\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"6622\",\"type\":\"CDSView\"}},\"id\":\"6621\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":4,\"x\":{\"field\":\"year\"},\"y\":{\"field\":\"rank\"}},\"id\":\"6615\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"6589\",\"type\":\"ColumnDataSource\"}},\"id\":\"6627\",\"type\":\"CDSView\"},{\"attributes\":{\"high\":20,\"low\":1,\"palette\":[\"#08306b\",\"#08316d\",\"#08326e\",\"#083370\",\"#083471\",\"#083573\",\"#083674\",\"#083776\",\"#083877\",\"#083979\",\"#083a7a\",\"#083b7c\",\"#083c7d\",\"#083d7f\",\"#083e81\",\"#084082\",\"#084184\",\"#084285\",\"#084387\",\"#084488\",\"#08458a\",\"#08468b\",\"#08478d\",\"#08488e\",\"#084990\",\"#084a91\",\"#084b93\",\"#084c95\",\"#084d96\",\"#084e98\",\"#084f99\",\"#08509b\",\"#08519c\",\"#09529d\",\"#0a539e\",\"#0a549e\",\"#0b559f\",\"#0c56a0\",\"#0d57a1\",\"#0e58a2\",\"#0e59a2\",\"#0f5aa3\",\"#105ba4\",\"#115ca5\",\"#125da6\",\"#125ea6\",\"#135fa7\",\"#1460a8\",\"#1561a9\",\"#1562a9\",\"#1663aa\",\"#1764ab\",\"#1865ac\",\"#1966ad\",\"#1967ad\",\"#1a68ae\",\"#1b69af\",\"#1c6ab0\",\"#1c6bb0\",\"#1d6cb1\",\"#1e6db2\",\"#1f6eb3\",\"#206fb4\",\"#2070b4\",\"#2171b5\",\"#2272b6\",\"#2373b6\",\"#2474b7\",\"#2575b7\",\"#2676b8\",\"#2777b8\",\"#2979b9\",\"#2a7ab9\",\"#2b7bba\",\"#2c7cba\",\"#2d7dbb\",\"#2e7ebc\",\"#2f7fbc\",\"#3080bd\",\"#3181bd\",\"#3282be\",\"#3383be\",\"#3484bf\",\"#3585bf\",\"#3686c0\",\"#3787c0\",\"#3888c1\",\"#3989c1\",\"#3a8ac2\",\"#3b8bc2\",\"#3c8cc3\",\"#3d8dc4\",\"#3e8ec4\",\"#3f8fc5\",\"#4090c5\",\"#4191c6\",\"#4292c6\",\"#4493c7\",\"#4594c7\",\"#4695c8\",\"#4896c8\",\"#4997c9\",\"#4a98c9\",\"#4b98ca\",\"#4d99ca\",\"#4e9acb\",\"#4f9bcb\",\"#519ccc\",\"#529dcc\",\"#539ecd\",\"#549fcd\",\"#56a0ce\",\"#57a0ce\",\"#58a1cf\",\"#5aa2cf\",\"#5ba3d0\",\"#5ca4d0\",\"#5da5d1\",\"#5fa6d1\",\"#60a7d2\",\"#61a7d2\",\"#63a8d3\",\"#64a9d3\",\"#65aad4\",\"#66abd4\",\"#68acd5\",\"#69add5\",\"#6aaed6\",\"#6caed6\",\"#6dafd7\",\"#6fb0d7\",\"#71b1d7\",\"#72b2d8\",\"#74b3d8\",\"#75b4d8\",\"#77b5d9\",\"#79b5d9\",\"#7ab6d9\",\"#7cb7da\",\"#7db8da\",\"#7fb9da\",\"#81badb\",\"#82bbdb\",\"#84bcdb\",\"#85bcdc\",\"#87bddc\",\"#89bedc\",\"#8abfdd\",\"#8cc0dd\",\"#8dc1dd\",\"#8fc2de\",\"#91c3de\",\"#92c4de\",\"#94c4df\",\"#95c5df\",\"#97c6df\",\"#99c7e0\",\"#9ac8e0\",\"#9cc9e1\",\"#9dcae1\",\"#9fcae1\",\"#a0cbe2\",\"#a1cbe2\",\"#a3cce3\",\"#a4cce3\",\"#a5cde3\",\"#a6cee4\",\"#a8cee4\",\"#a9cfe5\",\"#aacfe5\",\"#abd0e6\",\"#add0e6\",\"#aed1e7\",\"#afd1e7\",\"#b0d2e7\",\"#b2d2e8\",\"#b3d3e8\",\"#b4d3e9\",\"#b5d4e9\",\"#b7d4ea\",\"#b8d5ea\",\"#b9d6ea\",\"#bad6eb\",\"#bcd7eb\",\"#bdd7ec\",\"#bed8ec\",\"#bfd8ed\",\"#c1d9ed\",\"#c2d9ee\",\"#c3daee\",\"#c4daee\",\"#c6dbef\",\"#c7dbef\",\"#c7dcef\",\"#c8dcf0\",\"#c9ddf0\",\"#caddf0\",\"#cadef0\",\"#cbdef1\",\"#ccdff1\",\"#cddff1\",\"#cde0f1\",\"#cee0f2\",\"#cfe1f2\",\"#d0e1f2\",\"#d0e2f2\",\"#d1e2f3\",\"#d2e3f3\",\"#d3e3f3\",\"#d3e4f3\",\"#d4e4f4\",\"#d5e5f4\",\"#d6e5f4\",\"#d6e6f4\",\"#d7e6f5\",\"#d8e7f5\",\"#d9e7f5\",\"#d9e8f5\",\"#dae8f6\",\"#dbe9f6\",\"#dce9f6\",\"#dceaf6\",\"#ddeaf7\",\"#deebf7\",\"#dfebf7\",\"#dfecf7\",\"#e0ecf8\",\"#e1edf8\",\"#e2edf8\",\"#e3eef8\",\"#e3eef9\",\"#e4eff9\",\"#e5eff9\",\"#e6f0f9\",\"#e7f0fa\",\"#e7f1fa\",\"#e8f1fa\",\"#e9f2fa\",\"#eaf2fb\",\"#eaf3fb\",\"#ebf3fb\",\"#ecf4fb\",\"#edf4fc\",\"#eef5fc\",\"#eef5fc\",\"#eff6fc\",\"#f0f6fd\",\"#f1f7fd\",\"#f2f7fd\",\"#f2f8fd\",\"#f3f8fe\",\"#f4f9fe\",\"#f5f9fe\",\"#f5fafe\",\"#f6faff\",\"#f7fbff\"]},\"id\":\"6590\",\"type\":\"LinearColorMapper\"}],\"root_ids\":[\"6591\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"c5ca3b50-d612-487e-b629-1384f820b8ea\",\"roots\":{\"6591\":\"43e2a0d7-8fba-4d0e-b9ef-ebcf169b7d1f\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "6591"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "\n",
    "from bokeh.io import output_notebook,output_file, show, save\n",
    "output_notebook()\n",
    "\n",
    "from bokeh.models import ColumnDataSource, HoverTool, LinearColorMapper\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.palettes import Blues\n",
    "\n",
    "\n",
    "\n",
    "# x=df_2013['year']\n",
    "# y= df_2013['topic_n']\n",
    "size = vis_df['freq']/150\n",
    "\n",
    "source = ColumnDataSource(vis_df)\n",
    "\n",
    "t1 = vis_df[vis_df.topic_n == 1]\n",
    "st1 = ColumnDataSource(t1)\n",
    "\n",
    "t2 = vis_df[vis_df.topic_n == 2]\n",
    "st2 = ColumnDataSource(t2)\n",
    "\n",
    "t3 = vis_df[vis_df.topic_n == 3]\n",
    "st3 = ColumnDataSource(t3)\n",
    "\n",
    "cmap = LinearColorMapper(palette=Blues[256], \n",
    "                         low = min(vis_df[\"rank\"]), \n",
    "                         high = max(vis_df[\"rank\"]))\n",
    "\n",
    "p = figure(plot_width=800, plot_height=1000, title=\"Dominant Topic Frequency\", toolbar_location=None, tools=\"\")\n",
    "\n",
    "p.line(x='year', y='rank', source=st1, line_width = 4, line_color = 'grey', line_alpha=0.5)\n",
    "p.line(x='year', y='rank', source=st2, line_width = 4, line_color = 'grey', line_alpha=0.5)\n",
    "p.line(x='year', y='rank', source=st3, line_width = 4, line_color = 'grey', line_alpha=0.5)\n",
    "\n",
    "p.circle(x='year', y='rank', size = 30,source=source, \n",
    "         fill_color={\"field\":\"rank\", \"transform\":cmap})\n",
    "\n",
    "# for x in vis_df['topic_n'].unique():\n",
    "#     vis_df\n",
    "#     src = ColumnDataSource(vis_df[vis_df[topic_n] == x])\n",
    "\n",
    "\n",
    "p.add_tools(HoverTool(tooltips=[('Topic Number', '@topic_n'),\n",
    "                                (\"Frequency as Dominant Topic\", \"@freq\"),\n",
    "                                (\"Rank\", '@rank')]))\n",
    "\n",
    "from bokeh.models import ColorBar\n",
    "bar = ColorBar(color_mapper=cmap, location=(0,0))\n",
    "p.add_layout(bar, \"right\")\n",
    "\n",
    "\n",
    "\n",
    "show(p)\n",
    "\n",
    "# TO save the file as HTML\n",
    "#output_file(\"/Users/averysoh/Google Drive (racass1234@gmail.com)/AI Project/Avery_output/Dominant_topic.html\")\n",
    "#save(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T02:17:31.051118Z",
     "start_time": "2019-12-07T02:17:31.048577Z"
    }
   },
   "outputs": [],
   "source": [
    "Blues[256].reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T00:49:44.777463Z",
     "start_time": "2019-12-12T00:49:44.770217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "18\n",
      "8\n",
      "10\n",
      "4\n",
      "9\n",
      "7\n",
      "17\n",
      "19\n",
      "15\n",
      "16\n",
      "11\n",
      "3\n",
      "2\n",
      "12\n",
      "0\n",
      "1\n",
      "14\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for x in vis_df['topic_n'].unique():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T01:12:14.498717Z",
     "start_time": "2019-12-12T01:12:14.423676Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "19",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 19",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-16b805c664a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvis_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvis_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ai_project/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 19"
     ]
    }
   ],
   "source": [
    "vis_df[vis_df[topic_n] == 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T01:42:02.530242Z",
     "start_time": "2019-12-12T01:42:02.520238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>topic_n</th>\n",
       "      <th>freq</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4213</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6248</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7755</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>5497</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6035</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5665</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank  topic_n  freq  year\n",
       "16    17        1  4213  2013\n",
       "6      7        1  6248  2014\n",
       "0      1        1  7755  2015\n",
       "18    19        1  5497  2016\n",
       "4      5        1  6035  2017\n",
       "10    11        1  5665  2018"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_df[vis_df.topic_n == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus\n",
    "from gensim.models import LdaSeqModel\n",
    "\n",
    "ldaseq = LdaSeqModel(corpus=common_corpus, time_slice=[2, 4, 3], num_topics=2, chunksize=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
