{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-Directories\" data-toc-modified-id=\"Imports-and-Directories-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and Directories</a></span></li><li><span><a href=\"#Execution\" data-toc-modified-id=\"Execution-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Execution</a></span><ul class=\"toc-item\"><li><span><a href=\"#Processing-and-saving-the-file\" data-toc-modified-id=\"Processing-and-saving-the-file-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Processing and saving the file</a></span></li></ul></li><li><span><a href=\"#Get-100k-sample\" data-toc-modified-id=\"Get-100k-sample-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Get 100k sample</a></span></li><li><span><a href=\"#Get-1k-samples\" data-toc-modified-id=\"Get-1k-samples-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Get 1k samples</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T19:31:48.526834Z",
     "start_time": "2020-01-15T19:31:47.065868Z"
    }
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T19:31:48.682588Z",
     "start_time": "2020-01-15T19:31:48.679584Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import *\n",
    "#current working directory\n",
    "current_dir = Path.cwd()\n",
    "#go up 1 level to the 1st parent directory\n",
    "parent_dir = current_dir.parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T19:31:49.991531Z",
     "start_time": "2020-01-15T19:31:49.988192Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "def allDone():\n",
    "    '''this function outputs a short audio when called. \n",
    "    Typically this is used to signal a task completion'''\n",
    "    \n",
    "    display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T19:31:58.669253Z",
     "start_time": "2020-01-15T19:31:58.651763Z"
    }
   },
   "outputs": [],
   "source": [
    "# list used \n",
    "temp_list = ['jp morgan', 'jpm', 'jp-m', 'j.p. morgan', 'jpmorgan', \n",
    "'etoro', 'e-toro', 'e toroa', \n",
    "'visa',\n",
    "'goldman sachs', 'goldman-sachs', 'goldmansachs',\n",
    "'unilever',\n",
    "'deloitte',\n",
    "'google', 'alphabet',\n",
    "'wells-fargo', 'wells fargo',\n",
    "'allianz', 'allianz-inssurance',\n",
    "'samsung',\n",
    "'apple',\n",
    "'commerzbank']\n",
    "\n",
    "years = ['2013', '2014', '2015', '2016', '2017', '2018', '2019']\n",
    "#years = ['2013', '2014', '2015']\n",
    "\n",
    "\n",
    "com_list = [['JP Morgan',['jp morgan', 'jpm', 'jp-m', 'j.p. morgan', 'JPMorgan']],\n",
    "             ['Etoro',['etoro', 'e-toro', 'e toro']],\n",
    "             ['Google', ['google', 'alphabet']],\n",
    "             ['Visa', ['visa']],\n",
    "             ['Goldman Sachs', ['goldman sachs', 'goldman-sachs', 'goldmansachs']],\n",
    "             ['Unilever', ['unilever']],\n",
    "             ['Deloitte', ['deloitte']],\n",
    "             ['Samsung', ['samsung']],\n",
    "             ['Wells Fargo', ['wells-fargo', 'wells fargo']],\n",
    "             ['Allianz', ['allianz', 'allianz-inssurance']],\n",
    "             ['Apple', ['apple']],\n",
    "             ['Commerzbank', ['commerzbank']]]\n",
    "            \n",
    "\n",
    "\n",
    "company_list = ['JP Morgan', 'Etoro', 'Google', 'Visa', 'Goldman Sachs',\n",
    "               'Unilever', 'Deloitte', 'Samsung', 'Wells Fargo', 'Allianz',\n",
    "               'Apple', 'Commerzbank']\n",
    "\n",
    "\n",
    "# Cut by year\n",
    "reject2 = ['google.com', 'google play!', 'chinese google']\n",
    "\n",
    "\n",
    "def current_yr(df, year):\n",
    "    '''\n",
    "    df = original df from dask\n",
    "    year = taken from list\n",
    "    '''\n",
    "    df_year = df[df['date/time'].str.contains(year)]\n",
    "    \n",
    "    # Source from reference first\n",
    "    try:\n",
    "        clean_year = [tweet.lower() for tweet in df_year.tweet if any(tweet for ref in temp_list if str(ref) in tweet.lower())]\n",
    "    except:\n",
    "        clean_year = [str(tweet).lower() for tweet in df_year.tweet if any(tweet for ref in temp_list if str(ref) in str(tweet).lower())]\n",
    "        \n",
    "    # replace certain terms with empty to remove the companies for misreferenced tweets\n",
    "    clean_year_01 = clean_year\n",
    "    for rep in reject2:\n",
    "        clean_year_01 = [tweet.replace(rep, '') for tweet in clean_year_01]\n",
    "        \n",
    "    # Rerun to clean out all the non companies list ref\n",
    "    clean_year_02 = [tweet for tweet in clean_year_01 if any(tweet for ref in temp_list if str(ref) in tweet)]\n",
    "    \n",
    "    # Create the new df\n",
    "    df_avery = pd.DataFrame(columns = company_list)\n",
    "    df_avery['tweets'] = clean_year_02\n",
    "\n",
    "    matrix = [[] for x in range(len(company_list))]\n",
    "\n",
    "    for i in range(len(com_list)):\n",
    "        for j in range(len(df_avery)):\n",
    "            if  any(x in df_avery.tweets[j] for x in com_list[i][1]):\n",
    "                matrix[i].append(1)\n",
    "\n",
    "            else:\n",
    "                matrix[i].append(0)\n",
    "\n",
    "    df_avery[company_list] = np.transpose(matrix)\n",
    "    df_avery['year'] = year\n",
    "    print(year)\n",
    "    return df_avery\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T19:31:59.549635Z",
     "start_time": "2020-01-15T19:31:59.419239Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-06bf9c84a7d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date/time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2018'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_year = df[df['date/time'].str.contains('2018')]\n",
    "df_year.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date/time</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>216903</td>\n",
       "      <td>2016-01-25 23:59:55+00:00</td>\n",
       "      <td>Microsoft Releases Its Deep Learning Toolkit O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216904</td>\n",
       "      <td>2016-01-25 23:57:52+00:00</td>\n",
       "      <td>Drowning in #opensource these days | Microsoft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216905</td>\n",
       "      <td>2016-01-25 23:57:51+00:00</td>\n",
       "      <td>Microsoft releases #CNTK, its #opensource #dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216906</td>\n",
       "      <td>2016-01-25 23:57:45+00:00</td>\n",
       "      <td>Google's free 3 month course on deep learning:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date/time  \\\n",
       "216903  2016-01-25 23:59:55+00:00   \n",
       "216904  2016-01-25 23:57:52+00:00   \n",
       "216905  2016-01-25 23:57:51+00:00   \n",
       "216906  2016-01-25 23:57:45+00:00   \n",
       "\n",
       "                                                    tweet  \n",
       "216903  Microsoft Releases Its Deep Learning Toolkit O...  \n",
       "216904  Drowning in #opensource these days | Microsoft...  \n",
       "216905  Microsoft releases #CNTK, its #opensource #dee...  \n",
       "216906  Google's free 3 month course on deep learning:...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['date/time'].str.contains('2016')].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and saving the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T19:35:32.933684Z",
     "start_time": "2020-01-15T19:33:18.396640Z"
    }
   },
   "outputs": [],
   "source": [
    "# AI Part only\n",
    "\n",
    "# Data source\n",
    "data_path = parent_dir /'AI Project'/'Python Env'/'DataFrames'/'AI_datasets'/'globe_ai_13_18/*.csv'\n",
    "\n",
    "from glob import glob\n",
    "files = glob(str(data_path))\n",
    "df_files = [pd.read_csv(file, usecols=['tweet', 'date/time']) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T19:36:06.322006Z",
     "start_time": "2020-01-15T19:35:32.943400Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat(df_files, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T20:16:51.270198Z",
     "start_time": "2020-01-15T19:36:06.334490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_list = [current_yr(df, year) for year in years]\n",
    "\n",
    "# Save the file\n",
    "df_full = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "OUTPUT = parent_dir/'AI Project'/'Avery_output'/'AI_sequential_topic'\n",
    "outname ='AI_topic_company_full.csv'\n",
    "\n",
    "\n",
    "df_full.to_csv(os.path.join(str(OUTPUT),outname), index = False)\n",
    "\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(float(9.00)).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get 100k sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T20:16:51.292263Z",
     "start_time": "2020-01-15T20:16:51.282379Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_100k(n,df, year):\n",
    "    '''\n",
    "    n = number of samples to take\n",
    "    df= processed df \n",
    "    year= year selected\n",
    "    \n",
    "    Only collect 100k sample for each year\n",
    "    '''\n",
    "    \n",
    "    df1 = df[df['year'] == year]\n",
    "    if len(df1) > n:\n",
    "        df1 = df1.sample(n=n, random_state=11)\n",
    "        \n",
    "    else:\n",
    "        df1 = df1\n",
    "        print(year)\n",
    "        print(len(df1))\n",
    "    \n",
    "    return df1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 100k samples\n",
    "df_100_list = [get_100k(n=100000, df=df_full, year=year) for year in years]\n",
    "\n",
    "df_100 = pd.concat(df_100_list, ignore_index=True)\n",
    "\n",
    "OUTPUT = parent_dir/'AI Project'/'Avery_output'/'AI_sequential_topic'\n",
    "outname ='AI_topic_company_100k.csv'\n",
    "\n",
    "\n",
    "df_100.to_csv(os.path.join(str(OUTPUT),outname), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = parent_dir/'AI Project'/'Avery_output'/'AI_sequential_topic'\n",
    "outname ='AI_topic_company_100k.csv'\n",
    "\n",
    "df_100 = pd.read_csv(os.path.join(str(OUTPUT),outname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JP Morgan</th>\n",
       "      <th>Etoro</th>\n",
       "      <th>Google</th>\n",
       "      <th>Visa</th>\n",
       "      <th>Goldman Sachs</th>\n",
       "      <th>Unilever</th>\n",
       "      <th>Deloitte</th>\n",
       "      <th>Samsung</th>\n",
       "      <th>Wells Fargo</th>\n",
       "      <th>Allianz</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Commerzbank</th>\n",
       "      <th>tweets</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7 common #google analytics mistakes and how to...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>analyze organic search engine marketing with g...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the @visually google analytics report is prett...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>piwik - outil de mesure libre et open source d...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#c-sharp-programming integrate call data into ...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rt @mldcmu: #facebook joins #amazon and #googl...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#facebook joins #amazon and #google in #ai chi...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hello @scandalofmoney there is indeed life aft...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>online course deals! learn how to use google's...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>online course deals! learn how to use google's...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>675179 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        JP Morgan  Etoro  Google  Visa  Goldman Sachs  Unilever  Deloitte  \\\n",
       "0               0      0       1     0              0         0         0   \n",
       "1               0      0       1     0              0         0         0   \n",
       "2               0      0       1     0              0         0         0   \n",
       "3               0      0       1     0              0         0         0   \n",
       "4               0      0       1     0              0         0         0   \n",
       "...           ...    ...     ...   ...            ...       ...       ...   \n",
       "675174          0      0       1     0              0         0         0   \n",
       "675175          0      0       1     0              0         0         0   \n",
       "675176          0      0       1     0              0         0         0   \n",
       "675177          0      0       1     0              0         0         0   \n",
       "675178          0      0       1     0              0         0         0   \n",
       "\n",
       "        Samsung  Wells Fargo  Allianz  Apple  Commerzbank  \\\n",
       "0             0            0        0      0            0   \n",
       "1             0            0        0      0            0   \n",
       "2             0            0        0      0            0   \n",
       "3             0            0        0      0            0   \n",
       "4             0            0        0      0            0   \n",
       "...         ...          ...      ...    ...          ...   \n",
       "675174        0            0        0      0            0   \n",
       "675175        0            0        0      0            0   \n",
       "675176        0            0        0      0            0   \n",
       "675177        0            0        0      0            0   \n",
       "675178        0            0        0      0            0   \n",
       "\n",
       "                                                   tweets  year  \n",
       "0       7 common #google analytics mistakes and how to...  2013  \n",
       "1       analyze organic search engine marketing with g...  2013  \n",
       "2       the @visually google analytics report is prett...  2013  \n",
       "3       piwik - outil de mesure libre et open source d...  2013  \n",
       "4       #c-sharp-programming integrate call data into ...  2013  \n",
       "...                                                   ...   ...  \n",
       "675174  rt @mldcmu: #facebook joins #amazon and #googl...  2019  \n",
       "675175  #facebook joins #amazon and #google in #ai chi...  2019  \n",
       "675176  hello @scandalofmoney there is indeed life aft...  2019  \n",
       "675177  online course deals! learn how to use google's...  2019  \n",
       "675178  online course deals! learn how to use google's...  2019  \n",
       "\n",
       "[675179 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get 1k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T20:17:15.182603Z",
     "start_time": "2020-01-15T20:17:12.896454Z"
    }
   },
   "outputs": [],
   "source": [
    "# get 100k samples\n",
    "df_1_list = [get_100k(n=1000, df=df_full, year=year) for year in years]\n",
    "\n",
    "df_1 = pd.concat(df_1_list, ignore_index=True)\n",
    "\n",
    "OUTPUT = parent_dir/'AI Project'/'Avery_output'/'AI_sequential_topic'\n",
    "outname ='AI_topic_company_1k.csv'\n",
    "\n",
    "\n",
    "df_1.to_csv(os.path.join(str(OUTPUT),outname), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting tools\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#NLTK\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "if 'nlp' not in locals():\n",
    "    # nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from glob import glob\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Text Analysis (uncomment if running for first time)\n",
    "# ! wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "# ! unzip mallet-2.0.8.zip\n",
    "MALLET_PATH = 'mallet-2.0.8/bin/mallet'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
